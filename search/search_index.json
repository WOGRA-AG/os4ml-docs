{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Os4ML","text":"<p>Open space for Machine Learning (Os4ML) is an open source platform for  automated machine learning. The goal is to enable non-experts to solve  every day problems with AI. It automates all steps on the way to the  finished AI model with the help of an intuitive UI/UX.</p>"},{"location":"#about-the-project","title":"About the Project","text":"<p>The project focuses on easy installation, intuitive UI/UX and comfortable  machine learning. We're not reinventing the wheel. Whenever possible, we  use third-party open source software.</p> <p>The project is in an early phase, i.e. everything is work in progress and  experimental. In the fall of 2022, we had an alpha release for a select  group of users. We are currently in the process of stabilizing the platform so that we can open it up to a wider range of users in spring 2023.</p>"},{"location":"#license","title":"License","text":"<p>Os4ML is primarily distributed under the terms of both the MIT license and the Apache License (Version 2.0).</p> <p>See LICENSE-APACHE, LICENSE-MIT, and COPYRIGHT for details.</p>"},{"location":"about_us/","title":"About Us","text":"<p>Os4ML is a project of the WOGRA AG research group in cooperation with the  German Aerospace Center and is funded by the Ministry of Economic Affairs,  Regional Development and Energy as part of the High Tech Agenda of the  Free State of Bavaria.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Os4ML is designed as open source cloud-native application which runs on  Kubernetes clusters. On the one hand it consists of a set of multiple  python services using FastAPI and an Angular frontend. On the other  hand it uses standard frameworks for common problems like Keycloak for  authorization, Istio as ingress gateway, MinIO as high performance object storage and Kubeflow Pipelines as workflow engine. Thus,  Os4ML benefits from the development performance of a strong open source  community. This allows us to concentrate on high-level AI solutions.</p> <p></p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#image-classification","title":"Image Classification","text":"<ol> <li>Prepare a dataset according to the classification file format. Make sure that all images have the same format and size.</li> <li>Create a databag with this dataset. This should produce a databag with two columns one for the image and the other for the label.</li> <li>Create a solution and choose the label column as the output column.</li> </ol>"},{"location":"examples/#example-databags-for-common-machine-learning-problems","title":"Example Databags for common Machine Learning Problems","text":"<p>We will give some examples of how you can model your machine learning problem using the multimodal format.</p>"},{"location":"examples/#image-captioning-and-text2image","title":"Image Captioning and Text2Image","text":"column datatype image image description text <p>If you have a dataset with images and corresponding descriptions, you can train an image captioning model, by specifying the description as the output column. If you choose the image as the output column you can train a text2image model. However, this is not yet supported by our solvers, but will be a future feature.</p>"},{"location":"examples/#text-classification","title":"Text classification","text":"column datatype text text label categoy <p>Using a databag with a text column and a category column, you can model text classification tasks such as sentiment analysis.</p>"},{"location":"examples/#neural-machine-translation","title":"Neural Machine Translation","text":"column datatype languageA text languageB text <p>If you have a databag with translations from one language to another, you can train a neural machine translation model by simply selecting the desired language as the output column.</p>"},{"location":"file_formats/","title":"File formats","text":"<p>The following file formats are supported:</p>"},{"location":"file_formats/#tabular-data","title":"Tabular data","text":"type suffix example csv .csv Titanic dataset csv Excel .xls, .xlsx, .xlsm, .xlsb, .odf, .ods Titanic dataset excel <ul> <li>The first row contains the names of the columns.</li> <li>Only the first sheet of the Excel file is used.</li> </ul>"},{"location":"file_formats/#csv-format","title":"csv format","text":"<p>All common delimiters, including commas, colons, semicolons and tabs, are supported. For floating point numbers, please use dots as the decimal separator. Below is an example of a valid CSV file:</p> <pre><code>name,number,double\n\"Ford, Henry\",1.4,2.8\n\"Benz, Carl\",7.5,15.0\n</code></pre>"},{"location":"file_formats/#load-additional-files-eg-images","title":"Load additional files (e.g. images)","text":"<p>To load additional files such as images, create a column in the tabular dataset (csv or excel) with the file names.  Create a zip file of the tabular file along with the additional files. The zip file should contain only one csv file. The system will automatically detect that the column contains file names, and if they are present in the zip file, they will be loaded into your data bag.</p> type suffix example zip file .zip Mnist zip <p>Example structue of a zip file:</p> <pre><code>mnist\n\u251c\u2500\u2500 10.jpg\n\u251c\u2500\u2500 20.jpg\n\u251c\u2500\u2500 24.jpg\n\u2514\u2500\u2500 mnist.csv\n</code></pre> <p>Content of the mnist.csv:</p> <pre><code>image,digit\n10.jpg,3\n20.jpg,4\n24.jpg,1\n</code></pre> <ul> <li>Supported image files are: .jpg, .jpeg, .png, .tiff</li> <li>Currently only image files are supported, but in the future other files will be supported as well</li> </ul>"},{"location":"file_formats/#scripts","title":"Scripts","text":"type suffix example python script .py Python script <p>You can also upload python scripts that create a pandas dataframe. The script should save the dataframe as a csv without index in the location specified by the <code>--output</code> arg.</p>"},{"location":"installation/","title":"Installation","text":"<p>Nobody wants complicated installations. We neither. For this reason we  provided Terraform scripts in the past to install fully functional  Os4ML on a k3d cluster.</p>"},{"location":"installation/#k3d-cluster","title":"k3d cluster","text":"<p>k3d says it's 'a lightweight wrapper to run k3s (Rancher Lab\u2019s minimal  Kubernetes distribution) in docker'. Well yes, that's what it does, and it  does it great. We use k3d for daily development. Thus, you can assume  that Os4ML runs stably on k3d.</p> <p>With k3d you can do it like this, for example</p> <pre><code>git clone https://github.com/WOGRA-AG/terraform-kustomization-os4ml.git\ncd terraform-kustomization-os4ml\nk3d cluster create --config ./k3d-default.yaml\nterraform init\nterraform apply -auto-approve\n</code></pre>"},{"location":"installation/#gpu-support","title":"GPU Support","text":"<p>For sure, if you want to do machine learning, you want to use GPUs. So, what  about GPU support?</p> <p>Os4ML automatically uses GPUs if they are available in the Kubernetes  cluster. Unfortunately, GPUs are known to be a topic of their own. k3d describes  it in their documentation here.  If you have problems building the Docker image, remember to install the  <code>nvidia-container-toolkit</code> in addition to the <code>nvidia-container-runtime</code>.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>Let's first start with the basic terminology of os4ml. It is illustrated in the following picture:</p> <p></p>"},{"location":"introduction/#databag","title":"Databag","text":"<p>A databag is a convenient container for storing your data. You can easily create a databag by following the instructions in this tutorial, or explore the various file formats you can upload here. To manage the diversity of data types, we use the concept of multimodal data. Think of multimodal data as a table where each column is associated with a specific datatype, and the rows represent data corresponding to these columns.</p> <p>The petfinder dataset is an excellent example of multimodal data. For instance, it features Fenny, a dog(type 1) who is five years old and has been waiting for adoption for 100 days (AdoptionSpeed 4). The columns Type and AdoptionSpeed are categorical, the column Name contains text data, and Age is a numerical value. Additionally, the Image column contains image data.</p> <p></p>"},{"location":"introduction/#problem","title":"Problem","text":"<p>Based on a databag, you can define a problem to be solved by specifying one or more output columns to be predicted. In the petfinder dataset example, you would typically want to predict the 'AdoptionSpeed' column.</p> <p>Here you can find more examples that illustrate how to model your machine learning problem using the multimodal approach.</p>"},{"location":"introduction/#solver","title":"Solver","text":"<p>A Solver is an abstraction of an AI algorithm that can solve a specific problem, by training an AI model on data from a Databag to predict the specified columns. To explore available solvers, check out this list.</p>"},{"location":"introduction/#solution","title":"Solution","text":"<p>When a solver is executed on a problem, it produces a solution that can be used to predict values for unseen data. To learn how to create a solution using a solver, check out this tutorial.</p>"},{"location":"solvers/","title":"Solvers","text":"<p>Here you can find an overview of the currently supported solvers:</p>"},{"location":"solvers/#ludwig-solver","title":"Ludwig-Solver","text":"<p>The Ludwig-Solver is based on ludwig. Ludwig uses pytorch to create Encode-Combiner-Decoder models. A mixture of best practices and Hyperparameter Optimization strategies are used to train the model.</p>"},{"location":"tutorial/","title":"Tutorial","text":"<ol> <li> <p>Open get started dialog in the bottom left</p> <p></p> </li> <li> <p>Choose a name for the databag</p> <p></p> </li> <li> <p>Upload the dataset file</p> <ul> <li>Either upload the file directly of pass a valid url to it</li> <li>See File formats for more information on the supported file formats.</li> </ul> </li> <li> <p>Proceed and wait until the dataset is uploaded and inspected (this may take a while)</p> </li> <li> <p>Select the column you want to predict</p> <p></p> </li> <li> <p>Choose a name and a solver for the Solution. See Solvers for more information on the available solvers.</p> <p></p> </li> <li> <p>Wait until the solver is done</p> <p></p> </li> <li> <p>Go to the predictions page and open the 'Create prediction' dialog. Enter a name for the prediction and upload the data you want to predict. You download a template to see how your data should look like.</p> <p></p> </li> <li> <p>Click the predict button and wait until the prediction is done. Afterwards you can download your results.</p> </li> </ol>"}]}